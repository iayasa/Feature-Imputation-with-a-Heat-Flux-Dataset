{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prueba\n",
    "\n",
    "1. Vamos a cargar el dataset e importamos las librerias. \n",
    "\n",
    "2. Tras el análisis del EDA vamos a eliminiar las columnas \"author\" y \"geometry\". \n",
    "\n",
    "3. A continuación separamos el dataset en dos;\n",
    "<BR>\n",
    "\n",
    "i) Incluye los nulos (10.415) que será donde hagamos las prediciones.\n",
    "<BR>\n",
    "\n",
    "ii) No incluye los nulos (21.229) y será el que utilicemos para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31644, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos las librerias, cargamos el fichero y vemos las columnas. \n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "data_copia = data.copy()\n",
    "\n",
    "data_copia.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos después del relleno:\n",
      "pressure [MPa]         5500\n",
      "mass_flux [kg/m2-s]    5500\n",
      "D_e [mm]               5500\n",
      "D_h [mm]               5500\n",
      "length [mm]            5500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Función para rellenar los valores nulos con la media de la columna dentro de cada grupo de geometría\n",
    "def fill_nulls_with_group_mean(group):\n",
    "    return group.fillna(group.mean())\n",
    "\n",
    "# Rellenar los valores nulos en las columnas seleccionadas con la media de su grupo de geometría\n",
    "columns_to_fill = ['pressure [MPa]', 'mass_flux [kg/m2-s]', 'D_e [mm]', 'D_h [mm]', 'length [mm]']\n",
    "df_filled = data_copia.groupby('geometry')[columns_to_fill].transform(fill_nulls_with_group_mean)\n",
    "\n",
    "# Actualizar las columnas seleccionadas en el DataFrame original\n",
    "data_copia[columns_to_fill] = df_filled\n",
    "\n",
    "# Contar los valores nulos que quedan\n",
    "null_counts = data_copia[columns_to_fill].isnull().sum()\n",
    "\n",
    "print(\"Valores nulos después del relleno:\")\n",
    "print(null_counts)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos después del relleno:\n",
      "pressure [MPa]         0\n",
      "mass_flux [kg/m2-s]    0\n",
      "D_e [mm]               0\n",
      "D_h [mm]               0\n",
      "length [mm]            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Los valores nulos que quedan ahora los rellenaoms con la media de su columna. \n",
    "\n",
    "# Columnas para rellenar con la media de su columna\n",
    "columns_to_fill = ['pressure [MPa]', 'mass_flux [kg/m2-s]', 'D_e [mm]', 'D_h [mm]', 'length [mm]']\n",
    "\n",
    "# Rellenar los valores nulos en las columnas seleccionadas con la media de su columna\n",
    "data_copia[columns_to_fill] = data[columns_to_fill].fillna(data_copia[columns_to_fill].mean())\n",
    "\n",
    "# Contar los valores nulos que quedan\n",
    "null_counts = data_copia[columns_to_fill].isnull().sum()\n",
    "\n",
    "print(\"Valores nulos después del relleno:\")\n",
    "print(null_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                         0\n",
      "author                  5024\n",
      "geometry                5500\n",
      "pressure [MPa]             0\n",
      "mass_flux [kg/m2-s]        0\n",
      "x_e_out [-]            10415\n",
      "D_e [mm]                   0\n",
      "D_h [mm]                   0\n",
      "length [mm]                0\n",
      "chf_exp [MW/m2]            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar valores nulos en cada columna. \n",
    "\n",
    "valores_nulos = data_copia.isnull().sum()\n",
    "\n",
    "print(valores_nulos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_copia:  (31644, 10)\n",
      "Data con los NUN: (10415, 10)\n",
      "Data sin los NUN:  (21229, 10)\n"
     ]
    }
   ],
   "source": [
    "# Separo el nuevo DataFrame en dos:\n",
    "\n",
    "# Crear un DataFrame con filas que contienen NaN en 'x_e_out [-]'\n",
    "\n",
    "df_nan = data_copia[data_copia['x_e_out [-]'].isnull()]\n",
    "\n",
    "# Crear un DataFrame sin filas que contienen NaN en 'x_e_out [-]'\n",
    "\n",
    "df_sin_nan = data_copia[~data_copia['x_e_out [-]'].isnull()]\n",
    "\n",
    "print(\"Data_copia: \", data_copia.shape)\n",
    "print(\"Data con los NUN:\", df_nan.shape)\n",
    "print(\"Data sin los NUN: \", df_sin_nan.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de entrenar el modelo creamos el nuevo DF_sin NAN \n",
    "\n",
    "new_df_sin_nan = df_sin_nan.drop(['id', 'author', 'geometry'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "\n",
    "\n",
    "# Ahora vamos a entrenar el modelo \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = new_df_sin_nan.drop('x_e_out [-]', axis=1)\n",
    "y = df_sin_nan['x_e_out [-]']\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un objeto Scaler y ajustarlo a los datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar el modelo XGBoost con los mejores hiperparámetros\n",
    "modelo_XGB = XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100)\n",
    "modelo_XGB.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = modelo_XGB.predict(X_test_scaled)\n",
    "\n",
    "# Calcular el RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Calcular el R cuadrado\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calcular el MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular el MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
