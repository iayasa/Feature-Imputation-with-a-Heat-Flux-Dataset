{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost_GridSearchCV_sin Authory, Geometry e id.\n",
    "\n",
    "1. Vamos a cargar el dataset e importamos las librerias. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31644, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos las librerias, cargamos el fichero y vemos las columnas. \n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "data_copia = data.copy()\n",
    "\n",
    "data_copia.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rellenamos los valores nulos con la media de la columna pero dentro de cada uno de los grupos de geometria y luego vemos cuantos nulos siguen quedando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos después del relleno:\n",
      "pressure [MPa]         5500\n",
      "mass_flux [kg/m2-s]    5500\n",
      "D_e [mm]               5500\n",
      "D_h [mm]               5500\n",
      "length [mm]            5500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Función para rellenar los valores nulos con la media de la columna dentro de cada grupo de geometría\n",
    "def fill_nulls_with_group_mean(group):\n",
    "    return group.fillna(group.mean())\n",
    "\n",
    "# Rellenar los valores nulos en las columnas seleccionadas con la media de su grupo de geometría\n",
    "columns_to_fill = ['pressure [MPa]', 'mass_flux [kg/m2-s]', 'D_e [mm]', 'D_h [mm]', 'length [mm]']\n",
    "df_filled = data_copia.groupby('geometry')[columns_to_fill].transform(fill_nulls_with_group_mean)\n",
    "\n",
    "# Actualizar las columnas seleccionadas en el DataFrame original\n",
    "data_copia[columns_to_fill] = df_filled\n",
    "\n",
    "# Contar los valores nulos que quedan\n",
    "null_counts = data_copia[columns_to_fill].isnull().sum()\n",
    "\n",
    "print(\"Valores nulos después del relleno:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vemos que todavía quedan valores nulos y estos los imputamos con los valores nulos de la columna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos después del relleno:\n",
      "pressure [MPa]         0\n",
      "mass_flux [kg/m2-s]    0\n",
      "D_e [mm]               0\n",
      "D_h [mm]               0\n",
      "length [mm]            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Los valores nulos que quedan ahora los rellenaoms con la media de su columna. \n",
    "\n",
    "# Columnas para rellenar con la media de su columna\n",
    "columns_to_fill = ['pressure [MPa]', 'mass_flux [kg/m2-s]', 'D_e [mm]', 'D_h [mm]', 'length [mm]']\n",
    "\n",
    "# Rellenar los valores nulos en las columnas seleccionadas con la media de su columna\n",
    "data_copia[columns_to_fill] = data[columns_to_fill].fillna(data_copia[columns_to_fill].mean())\n",
    "\n",
    "# Contar los valores nulos que quedan\n",
    "null_counts = data_copia[columns_to_fill].isnull().sum()\n",
    "\n",
    "print(\"Valores nulos después del relleno:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los valores nulos que quedan son de columnas que vamos a eliminar o de la Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                         0\n",
      "author                  5024\n",
      "geometry                5500\n",
      "pressure [MPa]             0\n",
      "mass_flux [kg/m2-s]        0\n",
      "x_e_out [-]            10415\n",
      "D_e [mm]                   0\n",
      "D_h [mm]                   0\n",
      "length [mm]                0\n",
      "chf_exp [MW/m2]            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar valores nulos en cada columna. \n",
    "\n",
    "valores_nulos = data_copia.isnull().sum()\n",
    "\n",
    "print(valores_nulos)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separamos el Dataframe en dos.\n",
    "\n",
    "i) Un DataFrame con filas que contienen NaN en 'x_e_out [-]'\n",
    "\n",
    "ii)  Crear un DataFrame sin filas que contienen NaN en 'x_e_out [-]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_copia:  (31644, 10)\n",
      "Data con los NUN: (10415, 10)\n",
      "Data sin los NUN:  (21229, 10)\n"
     ]
    }
   ],
   "source": [
    "# Separo el nuevo DataFrame en dos:\n",
    "\n",
    "# Crear un DataFrame con filas que contienen NaN en 'x_e_out [-]'\n",
    "\n",
    "df_nan = data_copia[data_copia['x_e_out [-]'].isnull()]\n",
    "\n",
    "# Crear un DataFrame sin filas que contienen NaN en 'x_e_out [-]'\n",
    "\n",
    "df_sin_nan = data_copia[~data_copia['x_e_out [-]'].isnull()]\n",
    "\n",
    "print(\"Data_copia: \", data_copia.shape)\n",
    "print(\"Data con los NUN:\", df_nan.shape)\n",
    "print(\"Data sin los NUN: \", df_sin_nan.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de entrenar el modelo, vamos a eliminar aquellas columnas que no interesan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de entrenar el modelo creamos el nuevo DF_sin NAN \n",
    "\n",
    "new_df_sin_nan = df_sin_nan.drop(['id', 'author', 'geometry'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probamos el modelo de XG_Boost y sacamos las principales metricas para ver el rendimiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.07538441939952427\n",
      "R-squared: 0.4405357467533225\n",
      "Mean Squared Error (MSE): 0.005682810688203371\n",
      "Mean Absolute Error (MAE): 0.052361270102216376\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo\n",
    "\n",
    "# Ahora vamos a entrenar el modelo \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = new_df_sin_nan.drop('x_e_out [-]', axis=1)\n",
    "y = df_sin_nan['x_e_out [-]']\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un objeto Scaler y ajustarlo a los datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar el modelo XGBoost con los mejores hiperparámetros\n",
    "modelo_XGB = XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100)\n",
    "modelo_XGB.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = modelo_XGB.predict(X_test_scaled)\n",
    "\n",
    "# Calcular el RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Calcular el R cuadrado\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calcular el MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular el MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ponemos en el mismo formato el Data Frame de entrenamiento y aquel sobre el que vamos hacer las predicciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenar las columnas en df_nan para que coincida con el orden de new_df_sin_nan\n",
    "df_nan = df_nan[['id', 'pressure [MPa]', 'mass_flux [kg/m2-s]', 'x_e_out [-]', 'D_e [mm]', 'D_h [mm]', 'length [mm]', 'chf_exp [MW/m2]']]\n",
    "\n",
    "# Asegurarse de que las columnas estén en el mismo orden y tengan los mismos nombres\n",
    "df_nan.columns = ['id', 'pressure [MPa]', 'mass_flux [kg/m2-s]', 'x_e_out [-]', 'D_e [mm]', 'D_h [mm]', 'length [mm]', 'chf_exp [MW/m2]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure [MPa]</th>\n",
       "      <th>mass_flux [kg/m2-s]</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "      <th>D_e [mm]</th>\n",
       "      <th>D_h [mm]</th>\n",
       "      <th>length [mm]</th>\n",
       "      <th>chf_exp [MW/m2]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13.79</td>\n",
       "      <td>686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure [MPa]  mass_flux [kg/m2-s]  x_e_out [-]  D_e [mm]  D_h [mm]  \\\n",
       "4   4           13.79                686.0          NaN      11.1      11.1   \n",
       "\n",
       "   length [mm]  chf_exp [MW/m2]  \n",
       "4        457.0              2.8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_id = new_df_sin_nan['id']\n",
    "new_df_sin_nan = new_df_sin_nan.drop('id', axis=1)  # Eliminar la columna 'id' del DataFrame\n",
    "new_df_sin_nan.insert(0, 'id', column_id)  # Insertar la columna 'id' al principio del DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento del DataFrame df_nan\n",
    "df_nan_processed = df_nan.drop(['id', 'x_e_out [-]'], axis=1)  # Eliminar las columnas 'id' y 'x_e_out [-]'\n",
    "df_nan_scaled = scaler.transform(df_nan_processed)  # Aplicar el escalado\n",
    "\n",
    "# Realizar predicciones sobre df_nan preprocesado\n",
    "y_pred = modelo_XGB.predict(df_nan_scaled)  # Predicciones\n",
    "\n",
    "# Crear DataFrame para la presentación (submission)\n",
    "submission_df = pd.DataFrame({'id': df_nan['id'], 'x_e_out [-]': y_pred})\n",
    "\n",
    "# Guardar la presentación (submission) en un archivo CSV\n",
    "submission_df.to_csv('submission16.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
